{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbUCV1bpHPtm"
      },
      "outputs": [],
      "source": [
        "# Импорты\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Подключение Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGfFteaPHSjD"
      },
      "outputs": [],
      "source": [
        "# Константы и маппинг классов\n",
        "CLASS_MAPPING = {\n",
        "    'Potato_healthy': 2,\n",
        "    'Potato_sick_early': 1,\n",
        "    'Potato_sick_late': 0\n",
        "}\n",
        "\n",
        "# Функция загрузки данных\n",
        "def download_data(path_dataset):\n",
        "    data = []\n",
        "    labels = []\n",
        "    print(f\"Загрузка данных из: {path_dataset}\")\n",
        "    # Проходим по папкам-классам\n",
        "    for class_name in tqdm(sorted(os.listdir(path=path_dataset)), desc=\"Классы\"):\n",
        "        if class_name not in CLASS_MAPPING:\n",
        "            continue # Пропускаем файлы или папки, которых нет в маппинге\n",
        "\n",
        "        class_path = os.path.join(path_dataset, class_name)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        # Проходим по изображениям внутри папки\n",
        "        for filename in sorted(os.listdir(class_path)):\n",
        "            try:\n",
        "                full_path = os.path.join(class_path, filename)\n",
        "                image = Image.open(full_path).convert('RGB').resize((180, 180))\n",
        "                data.append(np.array(image))\n",
        "                labels.append(CLASS_MAPPING[class_name])\n",
        "            except Exception as e:\n",
        "                print(f\"Ошибка при обработке файла {filename}: {e}\")\n",
        "\n",
        "    return np.array(data), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Класс датасета\n",
        "class SimpleDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, labels, transform=None):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        # Переводим в тензор\n",
        "        self.transform = transform if transform else transforms.ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = self.transform(image) # Применяем трансформации\n",
        "        return image, torch.tensor(label).long() # Возвращаем тензор с меткой"
      ],
      "metadata": {
        "id": "43x48L83_7BS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Запуск загрузки и создание датасетов\n",
        "\n",
        "# Путь к данным\n",
        "base_path = '/content/drive/MyDrive/my_colab_data/Plants'\n",
        "train_path = os.path.join(base_path, 'Train')\n",
        "test_path = os.path.join(base_path, 'Test')\n",
        "\n",
        "# Загружаем numpy массивы\n",
        "train_data_np, train_labels_np = download_data(train_path)\n",
        "test_data_np, test_labels_np = download_data(test_path)\n",
        "\n",
        "# Экземпляры класса\n",
        "train_dataset = SimpleDataset(train_data_np, train_labels_np)\n",
        "test_dataset = SimpleDataset(test_data_np, test_labels_np)\n",
        "\n",
        "print(f\"\\nРазмер обучающей выборки: {len(train_dataset)}\")\n",
        "print(f\"Размер тестовой выборки: {len(test_dataset)}\")\n",
        "print(f\"Размер одного сэмпла (картинка): {train_dataset[0][0].shape}\")"
      ],
      "metadata": {
        "id": "Ho8fuDTeACeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Визуализация для проверки\n",
        "\n",
        "print(\"\\nПримеры изображений из датасета:\")\n",
        "plt.figure(figsize=(15, 5))\n",
        "# Отобразим по 3 картинки каждого класса\n",
        "indices = {0: [], 1: [], 2: []}\n",
        "for i, label in enumerate(train_labels_np):\n",
        "    if len(indices[label]) < 3:\n",
        "        indices[label].append(i)\n",
        "    if all(len(v) == 3 for v in indices.values()):\n",
        "        break\n",
        "\n",
        "plot_idx = 1\n",
        "for label_id, idx_list in indices.items():\n",
        "    for idx in idx_list:\n",
        "        plt.subplot(3, 3, plot_idx)\n",
        "        # Обратное преобразование для imshow: CHW -> HWC\n",
        "        plt.imshow(train_dataset[idx][0].permute(1, 2, 0))\n",
        "        # Находим имя класса по его ID\n",
        "        class_name = [k for k, v in CLASS_MAPPING.items() if v == label_id][0].replace(\"Potato_\", \"\")\n",
        "        plt.title(class_name)\n",
        "        plt.axis('off')\n",
        "        plot_idx += 1\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J3UeBZU3AOwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение архитектуры ResNet\n",
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResNetBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity # Сложение выхода с входом\n",
        "        out = self.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "wVafIfJ5AR3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Версия ResNet\n",
        "class SimpleResNet(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(SimpleResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        # Начальный блок\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Residual блоки\n",
        "        self.layer1 = self._make_layer(64, 2)\n",
        "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
        "\n",
        "        # Классификатор\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(256, num_classes)\n",
        "\n",
        "    def _make_layer(self, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "\n",
        "        if stride != 1 or self.in_channels != out_channels:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(ResNetBlock(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(ResNetBlock(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "print(\"Архитектура SimpleResNet определена\")"
      ],
      "metadata": {
        "id": "NalrV21sAhvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение SimpleResNet с нуля\n",
        "import torch.optim as optim\n",
        "# Гиперпараметры\n",
        "batch_size = 32\n",
        "num_classes = 3\n",
        "num_epochs = 10\n",
        "lr = 0.001\n",
        "\n",
        "# Загрузчики данных\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_scratch = SimpleResNet(num_classes=num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_scratch.parameters(), lr=lr)\n",
        "\n",
        "# Списки для хранения метрик\n",
        "history_scratch = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "\n",
        "print(\"Начинаем обучение SimpleResNet с нуля...\")\n",
        "for epoch in range(num_epochs):\n",
        "    # Фаза обучения\n",
        "    model_scratch.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Эпоха {epoch+1}/{num_epochs} [Обучение]\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_scratch(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_train_loss = running_loss / len(train_loader)\n",
        "    epoch_train_acc = correct / total\n",
        "    history_scratch['train_loss'].append(epoch_train_loss)\n",
        "    history_scratch['train_acc'].append(epoch_train_acc)\n",
        "\n",
        "    # Фаза валидации\n",
        "    model_scratch.eval()\n",
        "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model_scratch(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_val_loss = val_loss / len(test_loader)\n",
        "    epoch_val_acc = val_correct / val_total\n",
        "    history_scratch['val_loss'].append(epoch_val_loss)\n",
        "    history_scratch['val_acc'].append(epoch_val_acc)\n",
        "\n",
        "    print(f\"Эпоха {epoch+1}/{num_epochs} | \"\n",
        "          f\"Train Acc: {epoch_train_acc:.3f} | Val Acc: {epoch_val_acc:.3f} | \"\n",
        "          f\"Train Loss: {epoch_train_loss:.3f} | Val Loss: {epoch_val_loss:.3f}\")"
      ],
      "metadata": {
        "id": "bRlpDzNRAmD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Графики для SimpleResNet\n",
        "\n",
        "def plot_history(history, title):\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    epochs_range = range(1, len(history['train_acc']) + 1)\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, history['train_acc'], 'bo-', label='Точность на обучении')\n",
        "    plt.plot(epochs_range, history['val_acc'], 'ro-', label='Точность на валидации')\n",
        "    plt.title('Точность модели')\n",
        "    plt.xlabel('Эпохи')\n",
        "    plt.ylabel('Точность')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, history['train_loss'], 'bo-', label='Потери на обучении')\n",
        "    plt.plot(epochs_range, history['val_loss'], 'ro-', label='Потери на валидации')\n",
        "    plt.title('Потери модели')\n",
        "    plt.xlabel('Эпохи')\n",
        "    plt.ylabel('Потери')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history_scratch, \"Результаты обучения SimpleResNet с нуля\")"
      ],
      "metadata": {
        "id": "6kevg5GBArp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Настройка модели для Transfer Learning\n",
        "from torchvision import models\n",
        "\n",
        "# Загружаем предобученную модель ResNet-18\n",
        "model_tl = models.resnet18(pretrained=True)\n",
        "\n",
        "# \"Замораживаем\" все слои модели\n",
        "for param in model_tl.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Заменяем последний слой (классификатор)\n",
        "num_ftrs = model_tl.fc.in_features # Узнаем количество входов в последний слой\n",
        "# Создаем новый классификатор\n",
        "model_tl.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "# Переносим модель\n",
        "model_tl = model_tl.to(device)\n",
        "\n",
        "print(\"Предобученная модель ResNet-18 подготовлена для Transfer Learning\")\n",
        "print(\"Заморожены все слои, кроме последнего полносвязного (fc)\")"
      ],
      "metadata": {
        "id": "nfMpY5Q-Ek-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение с Transfer Learning\n",
        "import torch.optim as optim\n",
        "\n",
        "# Гиперпараметры.\n",
        "num_epochs_tl = 5\n",
        "lr_tl = 0.001\n",
        "\n",
        "# Параметры нового слоя\n",
        "optimizer_tl = optim.Adam(model_tl.fc.parameters(), lr=lr_tl)\n",
        "criterion_tl = nn.CrossEntropyLoss()\n",
        "\n",
        "history_tl = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "\n",
        "print(\"\\nНачинаем обучение с Transfer Learning\")\n",
        "for epoch in range(num_epochs_tl):\n",
        "    # Фаза обучения\n",
        "    model_tl.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Эпоха {epoch+1}/{num_epochs_tl} [Обучение]\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer_tl.zero_grad()\n",
        "        outputs = model_tl(images)\n",
        "        loss = criterion_tl(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_tl.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_train_loss = running_loss / len(train_loader)\n",
        "    epoch_train_acc = correct / total\n",
        "    history_tl['train_loss'].append(epoch_train_loss)\n",
        "    history_tl['train_acc'].append(epoch_train_acc)\n",
        "\n",
        "    # Фаза валидации\n",
        "    model_tl.eval()\n",
        "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model_tl(images)\n",
        "            loss = criterion_tl(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_val_loss = val_loss / len(test_loader)\n",
        "    epoch_val_acc = val_correct / val_total\n",
        "    history_tl['val_loss'].append(epoch_val_loss)\n",
        "    history_tl['val_acc'].append(epoch_val_acc)\n",
        "\n",
        "    print(f\"Эпоха {epoch+1}/{num_epochs_tl} | \"\n",
        "          f\"Train Acc: {epoch_train_acc:.3f} | Val Acc: {epoch_val_acc:.3f} | \"\n",
        "          f\"Train Loss: {epoch_train_loss:.3f} | Val Loss: {epoch_val_loss:.3f}\")\n",
        "\n",
        "# Визуализация результатов Transfer Learning\n",
        "plot_history(history_tl, \"Результаты обучения с Transfer Learning (ResNet-18)\")"
      ],
      "metadata": {
        "id": "beNcXStOEdTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Визуализация предсказаний\n",
        "\n",
        "def visualize_model_predictions(model, dataloader, class_names, num_images=16):\n",
        "\n",
        "    # Отображает изображения из батча и предсказания модели\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure(figsize=(16, 10))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        images, labels = next(iter(dataloader))\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        for i in range(num_images):\n",
        "            images_so_far += 1\n",
        "            ax = plt.subplot(num_images // 4, 4, images_so_far)\n",
        "            ax.axis('off')\n",
        "\n",
        "            # Предсказанная и истинная метки\n",
        "            pred_class = class_names[preds[i]].replace(\"Potato_\", \"\")\n",
        "            true_class = class_names[labels[i]].replace(\"Potato_\", \"\")\n",
        "\n",
        "            title_color = \"green\" if pred_class == true_class else \"red\"\n",
        "            ax.set_title(f\"Предсказание: {pred_class}\\n(Верно: {true_class})\", color=title_color)\n",
        "\n",
        "            # Отображаем изображение\n",
        "            img_display = images.cpu().data[i].permute(1, 2, 0).numpy()\n",
        "            ax.imshow(img_display)\n",
        "\n",
        "            if images_so_far == num_images:\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "                return\n",
        "\n",
        "test_loader_viz = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "class_names_list = ['Potato_sick_late', 'Potato_sick_early', 'Potato_healthy']\n",
        "\n",
        "visualize_model_predictions(model_tl, test_loader_viz, class_names_list)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "W_uzuhMqGHge"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}