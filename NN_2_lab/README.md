Ссылка на Colab:
https://colab.research.google.com/drive/13Z9nwTn947zhPRqYEIH04c2iAHr4_yGE?usp=sharing

# Лабораторная работа №2
Выполнила: Большова Елизавета Александровна

### Контрольные вопросы

**1. Сколько параметров содержится в каждом свёрточном слое?**

Количество обучаемых параметров в сверточном слое рассчитывается по формуле:
Параметры = (in_channels * kernel_height * kernel_width * out_channels) + out_channels_bias

Для модели MyAwesomeCNN:
*   **Conv1:** `(1 * 3 * 3 * 16) + 16 = 144 + 16 = 160 параметров`
*   **Conv2:** `(16 * 3 * 3 * 32) + 32 = 4608 + 32 = 4640 параметров`
*   **Conv3:** `(32 * 3 * 3 * 64) + 64 = 18432 + 64 = 18496 параметров`

---

**2. Как влияет MaxPool2d на размер выходного тензора?**

Слой `MaxPool2d` выполняет операцию даунсэмплинга (уменьшения разрешения). Он **уменьшает пространственные размеры** (высоту и ширину) тензора в `kernel_size` раз (в нашем случае в 2 раза), но при этом **не изменяет количество каналов** (глубину тензора).

---

**3. Что произойдёт при изменении количества выходных каналов в первом Conv2d?**

Изменение `out_channels` в первом сверточном слое вызовет **цепную реакцию**, так как выход одного слоя является входом для следующего:
1.  Необходимо будет изменить количество **входных каналов (`in_channels`)** в следующем сверточном слое (`conv2`), чтобы оно соответствовало новому количеству выходных каналов `conv1`. В противном случае возникнет ошибка несоответствия размеров тензоров.
2.  Общее количество обучаемых параметров в обоих слоях (`conv1` и `conv2`) также изменится.

---

**4. Чем отличаются режимы `eval()` и `train()` в PyTorch?**

Эти режимы управляют поведением слоев, которые по-разному работают во время обучения и инференса:

*   **`model.train()`:** Режим обучения. В этом режиме слои `Dropout` активны (случайным образом выключают нейроны для регуляризации), а слои `BatchNorm` обновляют свои внутренние статистики (среднее и дисперсию) на каждом батче.
*   **`model.eval()`:** Режим оценки/инференса. В этом режиме `Dropout` отключается (все нейроны работают), а `BatchNorm` замораживается и использует накопленные во время обучения статистики для нормализации данных. Это обеспечивает детерминированность и стабильность предсказаний модели.

---

**5. Какие преимущества даёт экспорт в формат ONNX?**

ONNX (Open Neural Network Exchange) — это открытый стандарт для представления моделей машинного обучения, который предоставляет несколько ключевых преимуществ:

*   **Переносимость (Interoperability):** Модель, созданную в одном фреймворке (например, PyTorch), можно без труда использовать в другом (TensorFlow, Keras) или в специализированных средах выполнения (TensorRT, OpenVINO).
*   **Оптимизация производительности:** ONNX-модели могут быть скомпилированы и оптимизированы для конкретного железа (CPU, GPU, FPGA, Edge-устройства), что часто приводит к значительному ускорению работы модели.
*   **Независимость от платформы:** Экспортированная модель становится независимой от языка программирования. Её можно интегрировать в приложения на C++, Java, C# или даже запустить в браузере с помощью ONNX.js.
*   **Удобная визуализация:** Формат позволяет легко анализировать, отлаживать и документировать архитектуру модели с помощью инструментов, таких как Netron.

### Анализ графа вычислений `my_new_cnn.onnx` в Netron

Структура разработанной нейронной сети `MyAwesomeCNN` была проанализирована с помощью визуализатора Netron.

![Скриншот графа](/NN_2_lab/image/screenshot_cnn_graph.png)

**Анализ сверточных слоев (Conv):**

*   **Conv1:**
    *   **Входной тензор:** `[batch_size, 1, 28, 28]`
    *   **Выходные каналы:** 16
    *   **Размер выходного тензора (после MaxPool):** `[batch_size, 16, 14, 14]`

*   **Conv2:**
    *   **Входной тензор:** `[batch_size, 16, 14, 14]`
    *   **Выходные каналы:** 32
    *   **Размер выходного тензора (после MaxPool):** `[batch_size, 32, 7, 7]`

*   **Conv3:**
    *   **Входной тензор:** `[batch_size, 32, 7, 7]`
    *   **Выходные каналы:** 64
    *   **Размер выходного тензора (после MaxPool):** `[batch_size, 64, 3, 3]`

**Анализ классификатора (полносвязные слои):**

Операция "выпрямления" тензора (`x.view(x.size(0), -1)`) в графе ONNX представлена набором операций (`Shape`, `Gather`, `Concat`, `Reshape`), которые в итоге преобразуют 4D-тензор в 2D-матрицу.

*   **Тензор перед flatten (`Reshape`):** `[batch_size, 64, 3, 3]`
*   **Тензор после flatten (вход в `fc1`):** `[batch_size, 576]` (так как 64 × 3 × 3 = 576)
*   **Тензор после `fc1` (вход в `fc2`):** `[batch_size, 128]`
*   **Финальный выходной тензор:** `[batch_size, 10]`

**Общее количество слоёв модели:**

Если считать каждую операцию в графе, то общее число слоев составляет **17**:
*   3 `Conv`
*   4 `Relu`
*   3 `MaxPool`
*   5 операций для `Reshape` (`Shape`, `Gather`, `Unsqueeze`, `Concat`, `Reshape`)
*   2 `Gemm` (полносвязные слои)
