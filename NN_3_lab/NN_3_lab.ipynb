{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "dwatQssLu7ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подключаем диск\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "gML9z02Du-mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqsKmtB1tpwK"
      },
      "outputs": [],
      "source": [
        "# Функция загрузки данных\n",
        "def load_data_from_path(path):\n",
        "    data = []\n",
        "    labels = []\n",
        "    print(f\"Загрузка данных из: {path}\")\n",
        "    for filename in tqdm(sorted(os.listdir(path))):\n",
        "        try:\n",
        "            # Собираем полный путь к файлу\n",
        "            full_path = os.path.join(path, filename)\n",
        "            # Открываем, конвертируем в RGB и меняем размер\n",
        "            image = Image.open(full_path).convert('RGB').resize((180, 180))\n",
        "            data.append(np.array(image))\n",
        "\n",
        "            # Определяем метку: 0 для 'cat', 1 для 'dog'\n",
        "            if 'cat' in filename:\n",
        "                labels.append(0)\n",
        "            else:\n",
        "                labels.append(1)\n",
        "        except Exception as e:\n",
        "            print(f\"Не удалось обработать файл {filename}: {e}\")\n",
        "\n",
        "    return np.array(data), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Запуск загрузки и визуализация\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/my_colab_data/Dogs-Cats/\"\n",
        "train_path = os.path.join(base_path, \"Train/\")\n",
        "test_path = os.path.join(base_path, \"Test/\")\n",
        "\n",
        "# Загружаем данные\n",
        "train_dataset_np, y_train_np = load_data_from_path(train_path)\n",
        "test_dataset_np, y_test_np = load_data_from_path(test_path)\n",
        "\n",
        "print(f\"\\nЗагружено {len(train_dataset_np)} обучающих изображений.\")\n",
        "print(f\"Загружено {len(test_dataset_np)} тестовых изображений.\")"
      ],
      "metadata": {
        "id": "FKAQC5O_vsxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Визуализация для проверки\n",
        "print(\"\\nПримеры изображений (кошки):\")\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(4):\n",
        "    plt.subplot(2, 4, i + 1)\n",
        "    plt.imshow(train_dataset_np[i])\n",
        "    plt.title(\"Cat\")\n",
        "    plt.axis('off')\n",
        "\n",
        "print(\"\\nПримеры изображений (собаки):\")\n",
        "dog_indices = np.where(y_train_np == 1)[0]\n",
        "for i in range(4):\n",
        "    plt.subplot(2, 4, i + 5)\n",
        "    plt.imshow(train_dataset_np[dog_indices[i]])\n",
        "    plt.title(\"Dog\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OrOoqP2Hv7lP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Предобработка данных и определение модели\n",
        "\n",
        "# Нормализуем данные в диапазон [0, 1] и меняем порядок осей: (N, H, W, C) -> (N, C, H, W)\n",
        "train_tensor = torch.tensor(train_dataset_np / 255.0, dtype=torch.float32).permute(0, 3, 1, 2)\n",
        "y_train_tensor = torch.tensor(y_train_np, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "test_tensor = torch.tensor(test_dataset_np / 255.0, dtype=torch.float32).permute(0, 3, 1, 2)\n",
        "y_test_tensor = torch.tensor(y_test_np, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# Создаем датасеты PyTorch\n",
        "train_tensor_dataset = TensorDataset(train_tensor, y_train_tensor)\n",
        "test_tensor_dataset = TensorDataset(test_tensor, y_test_tensor)\n",
        "\n",
        "# Определяем устройство (GPU или CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Используемое устройство: {device}\")\n",
        "\n",
        "# Определяем архитектуру модели\n",
        "class CNNBinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNBinaryClassifier, self).__init__()\n",
        "        # Блок 1\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        # Блок 2\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        # Блок 3\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2) # Пул после каждого блока\n",
        "\n",
        "        # Динамическое вычисление размера для FC слоя\n",
        "        with torch.no_grad():\n",
        "            # Прогоняем пустышку через сверточную часть, чтобы узнать размер выхода\n",
        "            dummy_input = torch.zeros(1, 3, 180, 180)\n",
        "            x = self.pool(F.relu(self.bn1(self.conv1(dummy_input))))\n",
        "            x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "            x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "            self.flattened_size = x.view(1, -1).size(1)\n",
        "\n",
        "        # Полносвязная часть\n",
        "        self.fc1 = nn.Linear(self.flattened_size, 512)\n",
        "        self.fc2 = nn.Linear(512, 1) # Один выход для бинарной классификации\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = x.view(x.size(0), -1) # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x) # Без сигмоиды, так как BCEWithLogitsLoss\n",
        "        return x"
      ],
      "metadata": {
        "id": "sIKN8ju-xAQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e4f9dc6-ca3e-42ec-a01d-41bd13323c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используемое устройство: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели БЕЗ аугментации\n",
        "\n",
        "# Гиперпараметры\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "# Создаем загрузчики данных\n",
        "train_loader = DataLoader(train_tensor_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_tensor_dataset, batch_size=batch_size)\n",
        "\n",
        "# Инициализируем модель, лосс и оптимизатор\n",
        "model_no_aug = CNNBinaryClassifier().to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model_no_aug.parameters(), lr=learning_rate)\n",
        "\n",
        "# Списки для хранения метрик\n",
        "history_no_aug = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "\n",
        "print(\"Начинаем обучение модели БЕЗ аугментации\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Обучение\n",
        "    model_no_aug.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Эпоха {epoch+1}/{num_epochs} [Обучение]\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_no_aug(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        preds = torch.sigmoid(outputs) > 0.5\n",
        "        correct_train += (preds == labels).sum().item()\n",
        "        total_train += labels.size(0)\n",
        "\n",
        "    epoch_train_loss = running_loss / total_train\n",
        "    epoch_train_acc = correct_train / total_train\n",
        "    history_no_aug['train_loss'].append(epoch_train_loss)\n",
        "    history_no_aug['train_acc'].append(epoch_train_acc)\n",
        "\n",
        "    # Валидация\n",
        "    model_no_aug.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model_no_aug(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            correct_val += (preds == labels).sum().item()\n",
        "            total_val += labels.size(0)\n",
        "\n",
        "    epoch_val_loss = val_loss / total_val\n",
        "    epoch_val_acc = correct_val / total_val\n",
        "    history_no_aug['val_loss'].append(epoch_val_loss)\n",
        "    history_no_aug['val_acc'].append(epoch_val_acc)\n",
        "\n",
        "    print(f\"Эпоха {epoch+1}/{num_epochs} | \"\n",
        "          f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f} | \"\n",
        "          f\"Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}\")\n",
        "\n",
        "print(\"\\nОбучение без аугментации завершено\")"
      ],
      "metadata": {
        "id": "Xc3qiOeqxZYR",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Визуализация результатов\n",
        "def plot_history(history, title):\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    # График точности\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['train_acc'], label='Точность на обучении')\n",
        "    plt.plot(history['val_acc'], label='Точность на валидации')\n",
        "    plt.title('Точность модели')\n",
        "    plt.ylabel('Точность')\n",
        "    plt.xlabel('Эпоха')\n",
        "    plt.legend()\n",
        "\n",
        "    # График потерь\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['train_loss'], label='Потери на обучении')\n",
        "    plt.plot(history['val_loss'], label='Потери на валидации')\n",
        "    plt.title('Потери модели')\n",
        "    plt.ylabel('Потери')\n",
        "    plt.xlabel('Эпоха')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history_no_aug, \"Результаты обучения БЕЗ аугментации\")"
      ],
      "metadata": {
        "id": "9ouusokNxtwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение аугментаций\n",
        "\n",
        "# Трансформации для обучающего набора данных\n",
        "# ToPILImage() нужен для numpy массивов\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomHorizontalFlip(p=0.5), # Случайное горизонтальное отражение\n",
        "    transforms.RandomRotation(degrees=20),    # Случайный поворот на угол до 20 градусов\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # Случайное изменение яркости/контраста\n",
        "    transforms.ToTensor(), # Преобразуем в тензор\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Стандартная нормализация\n",
        "])\n",
        "\n",
        "# Трансформации для тестового набора\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Визуализируем, как работает аугментация\n",
        "print(\"Примеры аугментации для одного изображения:\")\n",
        "image_np = train_dataset_np[0] # Берем первую кошку\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(9):\n",
        "    augmented_image = train_transforms(image_np)\n",
        "    # Делаем обратное преобразование для корректного отображения\n",
        "    img_to_show = augmented_image.permute(1, 2, 0).numpy()\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    img_to_show = std * img_to_show + mean\n",
        "    img_to_show = np.clip(img_to_show, 0, 1)\n",
        "\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(img_to_show)\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gcJOksFA33mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CustomDataset и модель с Dropout\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "# Создаем датасеты с аугментацией\n",
        "train_dataset_aug = CustomImageDataset(train_dataset_np, y_train_np, transform=train_transforms)\n",
        "test_dataset_aug = CustomImageDataset(test_dataset_np, y_test_np, transform=test_transforms)\n",
        "\n",
        "# Модель, идентичная предыдущей, но с добавлением Dropout\n",
        "class CNNWithDropout(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNWithDropout, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Динамический расчет размера\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, 3, 180, 180)\n",
        "            x = self.pool(F.relu(self.bn1(self.conv1(dummy_input))))\n",
        "            x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "            x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "            self.flattened_size = x.view(1, -1).size(1)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.flattened_size, 512)\n",
        "        self.dropout = nn.Dropout(p=0.5) # Добавляем Dropout с вероятностью 0.5\n",
        "        self.fc2 = nn.Linear(512, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x) # Применяем Dropout перед последним слоем\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kqpoWOmU45BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели c аугментацией\n",
        "\n",
        "# Гиперпараметры\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 80\n",
        "batch_size = 32\n",
        "\n",
        "# Создаем загрузчики данных\n",
        "train_loader_aug = DataLoader(train_dataset_aug, batch_size=batch_size, shuffle=True)\n",
        "test_loader_aug = DataLoader(test_dataset_aug, batch_size=batch_size)\n",
        "\n",
        "# Инициализация\n",
        "model_with_aug = CNNWithDropout().to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model_with_aug.parameters(), lr=learning_rate)\n",
        "\n",
        "history_with_aug = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "\n",
        "print(\"Начинаем обучение модели С аугментацией и Dropout...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Фаза обучения\n",
        "    model_with_aug.train()\n",
        "    running_loss, correct_train, total_train = 0.0, 0, 0\n",
        "    for images, labels in tqdm(train_loader_aug, desc=f\"Эпоха {epoch+1}/{num_epochs} [Обучение]\"):\n",
        "        images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_with_aug(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        preds = torch.sigmoid(outputs) > 0.5\n",
        "        correct_train += (preds == labels).sum().item()\n",
        "        total_train += labels.size(0)\n",
        "    epoch_train_loss = running_loss / total_train\n",
        "    epoch_train_acc = correct_train / total_train\n",
        "    history_with_aug['train_loss'].append(epoch_train_loss)\n",
        "    history_with_aug['train_acc'].append(epoch_train_acc)\n",
        "\n",
        "    # Фаза валидации\n",
        "    model_with_aug.eval()\n",
        "    val_loss, correct_val, total_val = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader_aug:\n",
        "            images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
        "            outputs = model_with_aug(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            correct_val += (preds == labels).sum().item()\n",
        "            total_val += labels.size(0)\n",
        "    epoch_val_loss = val_loss / total_val\n",
        "    epoch_val_acc = correct_val / total_val\n",
        "    history_with_aug['val_loss'].append(epoch_val_loss)\n",
        "    history_with_aug['val_acc'].append(epoch_val_acc)\n",
        "\n",
        "    print(f\"Эпоха {epoch+1}/{num_epochs} | \"\n",
        "          f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f} | \"\n",
        "          f\"Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}\")\n",
        "\n",
        "print(\"\\nОбучение с аугментацией завершено.\")\n",
        "\n",
        "# Визуализация результатов\n",
        "plot_history(history_with_aug, \"Результаты обучения С аугментацией и Dropout\")"
      ],
      "metadata": {
        "id": "8s-MC6NL5HXd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}