{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Импорт библиотек\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid"
      ],
      "metadata": {
        "id": "5ypIuCkUwvwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "F9mnBtIOOlBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение всех функций\n",
        "\n",
        "def prepare_dataset(path_dataset, output_dir='./processed_data', csv_path='./plant_dataset.csv'):\n",
        "\n",
        "    # Преобразуем изображения и сохраняем информацию в CSV\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    data_info = []\n",
        "    label_map = {\n",
        "        'Potato_healthy': 2,\n",
        "        'Potato_sick_early': 1,\n",
        "        'Potato_sick_late': 0\n",
        "    }\n",
        "\n",
        "    idx = 0\n",
        "    for path_dir in sorted(os.listdir(path_dataset)):\n",
        "        full_dir = os.path.join(path_dataset, path_dir)\n",
        "        if not os.path.isdir(full_dir):\n",
        "            continue\n",
        "        label = label_map.get(path_dir)\n",
        "        if label is None:\n",
        "            continue\n",
        "\n",
        "        print(f\"Обработка папки: {path_dir}\")\n",
        "        for filename in tqdm(sorted(os.listdir(full_dir))):\n",
        "            full_path = os.path.join(full_dir, filename)\n",
        "            try:\n",
        "                image = Image.open(full_path).convert(\"RGB\").resize((180, 180))\n",
        "                save_path = os.path.join(output_dir, f'{idx}.png')\n",
        "                image.save(save_path)\n",
        "                data_info.append([save_path, label])\n",
        "                idx += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Не удалось обработать файл {full_path}: {e}\")\n",
        "\n",
        "    df = pd.DataFrame(data_info, columns=['image_path', 'label'])\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"\\nИнформация о датасете ({len(df)} изображений) сохранена в {csv_path}\")"
      ],
      "metadata": {
        "id": "Z8g8pVFTK4yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.data.loc[idx, 'image_path']\n",
        "        label = self.data.loc[idx, 'label']\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "def dummy_loss_function(outputs, targets):\n",
        "    # Заглушка для функции\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    return loss_fn(outputs, targets)\n",
        "\n",
        "def iterate_dataloader(dataloader, num_classes):\n",
        "    for images, labels in tqdm(dataloader, desc=\"Итерация по батчам\", leave=False):\n",
        "        # Имитация работы модели\n",
        "        current_batch_size = images.shape[0]\n",
        "        dummy_logits = torch.randn(current_batch_size, num_classes)\n",
        "        loss = dummy_loss_function(dummy_logits, labels)\n",
        "    # Возвращаем последний батч для возможной визуализации\n",
        "    return images, labels\n",
        "\n",
        "def evaluate_pipeline_performance(dataset, num_classes):\n",
        "    # Сетка параметров для тестирования\n",
        "    batch_sizes = [16, 64, 128]\n",
        "    num_workers_list = [0, 2, 4]\n",
        "    results = []\n",
        "\n",
        "    # Последний батч для визуализации\n",
        "    last_batch_for_viz = None\n",
        "\n",
        "    for batch_size in batch_sizes:\n",
        "        for num_workers in num_workers_list:\n",
        "            print(f\"\\nТестируем: batch_size={batch_size}, num_workers={num_workers}\")\n",
        "\n",
        "            loader = DataLoader(\n",
        "                dataset,\n",
        "                batch_size=batch_size,\n",
        "                num_workers=num_workers,\n",
        "                shuffle=True\n",
        "            )\n",
        "\n",
        "            start_time = time.time()\n",
        "            # Запускаем полный проход по данным\n",
        "            images, labels = iterate_dataloader(loader, num_classes)\n",
        "            elapsed_time = time.time() - start_time\n",
        "\n",
        "            results.append({\n",
        "                'Batch Size': batch_size,\n",
        "                'Num Workers': num_workers,\n",
        "                'Время (секунды)': elapsed_time\n",
        "            })\n",
        "            print(f\"-> Общее время: {elapsed_time:.2f} секунд\")\n",
        "\n",
        "            # Сохраняем батч от последней итерации для визуализации\n",
        "            last_batch_for_viz = (images, labels)\n",
        "\n",
        "    return results, last_batch_for_viz"
      ],
      "metadata": {
        "id": "Qvt9Rb8MLUmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Для визуализации батча\n",
        "def visualize_batch(images, labels, class_names):\n",
        "\n",
        "    num_to_show = min(24, len(images))\n",
        "\n",
        "    # Де-нормализация для корректного отображения цветов\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "    # Создаем фигуру с сеткой 3x8\n",
        "    fig, axes = plt.subplots(3, 8, figsize=(22, 9))\n",
        "    fig.suptitle(\"Визуализация изображений из последнего батча\", fontsize=20)\n",
        "\n",
        "    # Превращаем сетку осей в плоский список для удобной итерации\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i in range(num_to_show):\n",
        "        ax = axes[i]\n",
        "\n",
        "        # Переводим тензор в numpy и де-нормализуем\n",
        "        img_np = images[i].permute(1, 2, 0).numpy()\n",
        "        img_denorm = std * img_np + mean\n",
        "        img_denorm = np.clip(img_denorm, 0, 1)\n",
        "\n",
        "        ax.imshow(img_denorm)\n",
        "\n",
        "        # Добавляем текст на изображение\n",
        "        label_text = class_names[labels[i].item()]\n",
        "        ax.text(5, 15, label_text,\n",
        "                 color='white',\n",
        "                 backgroundcolor='black',\n",
        "                 fontsize=10,\n",
        "                 fontweight='bold',\n",
        "                 # Добавим небольшой бокс вокруг текста\n",
        "                 bbox=dict(facecolor='black', alpha=0.5, pad=1))\n",
        "\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "    for i in range(num_to_show, len(axes)):\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "yZpVPSM7Lzfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Основной блок выполнения вынесла сюда\n",
        "\n",
        "PATH_TO_TRAIN_DATA = \"/content/drive/MyDrive/my_colab_data/Plants/Train/\"\n",
        "PROCESSED_DATA_DIR = './processed_data'\n",
        "CSV_PATH = './plant_dataset.csv'\n",
        "CLASSES = {0: 'sick_late', 1: 'sick_early', 2: 'healthy'}\n",
        "\n",
        "if not os.path.exists(CSV_PATH):\n",
        "    prepare_dataset(path_dataset=PATH_TO_TRAIN_DATA, output_dir=PROCESSED_DATA_DIR, csv_path=CSV_PATH)\n",
        "else:\n",
        "    print(f\"Файл {CSV_PATH} уже существует, подготовка данных пропущена.\")\n",
        "\n",
        "# Объединяем все трансформации в один пайплайн\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = CustomDataset(csv_file=CSV_PATH, transform=transform)\n",
        "print(f\"Датасет создан, количество изображений: {len(dataset)}\")\n",
        "\n",
        "# Оценка производительности\n",
        "performance_results, last_batch = evaluate_pipeline_performance(dataset, num_classes=len(CLASSES))\n",
        "\n",
        "# Результат\n",
        "results_df = pd.DataFrame(performance_results)\n",
        "print(\"\\nИтоговая таблица производительности\")\n",
        "print(results_df.to_markdown(index=False, tablefmt=\"grid\"))\n",
        "\n",
        "# Визуализируем последний батч\n",
        "if last_batch:\n",
        "    images, labels = last_batch\n",
        "    visualize_batch(images, labels, CLASSES)"
      ],
      "metadata": {
        "id": "5G16kzAzMgnt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}