Ссылка на Colab:

https://colab.research.google.com/drive/1l0rFFYjtXoAMhAjJt9MbJHvafNHKjtGr?usp=sharing

# Лабораторная работа №5
Выполнила: Большова Елизавета Александровна

### Итоговые выводы по лабораторной работе

В ходе работы было проведено сравнение двух подходов к решению задачи семантической сегментации: обучение архитектуры U-Net с нуля и использование U-Net с предобученным энкодером на базе VGG-16 (Transfer Learning).

**U-Net, обученный с нуля**
*   **Процесс обучения:** модель обучалась, но крайне нестабильно. График потерь на валидационной выборке показывал сильные колебания, что свидетельствует о неспособности модели найти устойчивое решение на небольшом наборе данных.

![Обучение GTA5](/NN_5_lab/image/result_U-Net.jpg)

*   **Качество сегментации:** итоговые маски получились очень "шумными" и грубыми. Модель смогла уловить только общие контуры крупных объектов (дорога, небо), но полностью провалилась в сегментации мелких деталей и точной отрисовке границ.

![Пример mask GTA5](/NN_5_lab/image/results_U-Net.jpg)

**U-Net на базе предобученного VGG-16**

Использование VGG-16 в качестве энкодера и "заморозка" его весов привели к кардинальному улучшению по всем параметрам:
*   **Процесс обучения:** обучение проходило очень быстро и стабильно. Модель достигла низкого и устойчивого значения функции потерь на валидации всего за несколько эпох.

![Обучение GTA5](/NN_5_lab/image/result_VGG.jpg)

*   **Качество сегментации:** качество предсказанных масок **существенно возросло**. Границы объектов стали четкими, исчезли шумовые артефакты, и, что самое важное, модель научилась корректно сегментировать мелкие и удаленные объекты, которые ранее игнорировались.

![Пример mask GTA5](/NN_5_lab/image/results_VGG.jpg)

### Заключение

Сравнение однозначно доказывает **огромное преимущество Transfer Learning** в задачах компьютерного зрения, особенно при работе с ограниченными данными. Использование предобученного энкодера (backbone) позволяет передать модели фундаментальные знания о визуальных признаках, полученные на миллионах изображений. Это не только **ускоряет и стабилизирует процесс обучения в десятки раз**, но и позволяет достичь **значительно более высокого качества** и точности итоговых предсказаний.
